# LLM Scheduler 配置文件
app:
  name: "LLM Scheduler"
  version: "1.0.0"
  env: "development"  # development, live

server:
  host: "0.0.0.0"
  port: 8080
  read_timeout: 60s
  write_timeout: 60s

database:
  host: "localhost"
  port: 3306
  username: "llm_user"
  password: "llm_password"
  database: "llm_scheduler"
  charset: "utf8mb4"
  parse_time: true
  loc: "Local"
  max_idle_conns: 10
  max_open_conns: 100
  conn_max_lifetime: "1h"

redis:
  host: "localhost"
  port: 6379
  db: 0
  password: ""
  pool_size: 10
  min_idle_conns: 5

queue:
  # 任务队列配置
  high_priority_queue: "llm_tasks:high"
  medium_priority_queue: "llm_tasks:medium" 
  low_priority_queue: "llm_tasks:low"
  delayed_queue: "llm_tasks:delayed"
  processing_queue: "llm_tasks:processing"
  # 队列长度限制
  max_queue_size: 10000
  # 任务处理超时时间
  task_timeout: "300s"
  # 任务重试配置
  max_retries: 3
  retry_delay: "60s"

worker:
  # Worker 池配置
  default_workers: 5
  max_workers: 50
  worker_timeout: "300s"
  # 心跳间隔
  heartbeat_interval: "30s"

logging:
  level: "info"  # debug, info, warn, error
  format: "json"  # json, text
  output: "stdout"  # stdout, file
  file_path: "logs/app.log"
  max_size: 100  # MB
  max_age: 30    # days
  max_backups: 10
  compress: true

cors:
  allow_origins: ["http://localhost:3000", "http://127.0.0.1:3000"]
  allow_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
  allow_headers: ["Content-Type", "Authorization", "X-Requested-With"]
  expose_headers: ["Content-Length"]
  allow_credentials: true
  max_age: "12h"

# LLM 模型默认配置
models:
  openai:
    base_url: "https://api.openai.com/v1"
    timeout: "60s"
    max_retries: 3
  
  local:
    timeout: "120s"
    max_retries: 2
